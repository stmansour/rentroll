How To Use And Develop Tests In This Directory

Developers: Please add notes here to anything that is missing.

1. Add a directory for each area of focus on your functional
   tests.

2. Using the functions in ./share/base.sh will save you a lot
   of time and effort. Try to use them as much as possible.
   It will save you a lot of time. If there is some functionality
   you need that does not exist in base.sh, add it to base.sh
   rather than doing one-off work in your directory.

3. Makefiles MUST support the targets 'clean', 'package', and
   'test'.

4. Each test directory needs to be self-contained - it must not
   depend on the output of other tests.  If you have an exception
   to this, please contact sman@accordinterests.com and let's
   discuss.

5. NO LONGER NEED TO DO THIS.  I have updated the script to just work
   on all databases.  It used to require that files you wanted to be tested
   be listed in dbfiles.txt.

6. If you make a change the the rentroll schema, please update dbmod.sh
   with the ALTER statements (or whatever) needed to bring existing
   databases in sync with the updated schema. Then run dbmod.sh to
   bring all the test databases up to date. Once you have run dbmode.sh
   move your changes into the comments above along with the date that
   you applied them.  This will serve as notes for updating the
   production schemas.

7. If you create a .sql file to use as the database for your functional
   test, you need to add the filename to dbfiles.txt.
   This will ensure that the schema is correct before any of the
   functional tests are run during 'make test'.

8. You should always check the schema of your .sql files to ensure that they
   are in sync with the latest schema.  There is a general purpose script for
   this: localcmp.sh .  This script compares the schema of all
   the database files listed in dbfiles.txt.  Whenever you add a db file to
   a test directory, always be sure to add it into dbfiles.txt. localcmp.sh
   generates dbreport.txt .

9. Do not push updates to the github repo if localcmp.sh fails, fix them.

10. The files sqlschema/fixprod.sh and sqlschema/fixrcpts.sh are scripts
    that update the production databases based on all the changes we make.
    You will need to update them as well as dbmod.sh.

11. All test cases should be documented. Describe what the test
    does and what the expected results are.  If you don't do this
    you probably won't remember the details of what you were doing
    six months after you wrote it and one of your code changes
    breaks the test.

12. The main script for running the test is named functest.sh by
    convention.  Individual tests within functest.sh can be created
    in sections referred to by name. This makes them easier to
    document, and it makes it possible to run them individually
    for debugging purposes. A good example of this can be seen in
    ./raflow/f2ra/functest.sh

    * There are many environment variables used within the functions in
      base.sh. You can set these variables prior to calling the functions
      as needed.  They need to all be documented, but as of this writing
      they are not.  Here are some important env vars that you must understand
      before writing or debugging tests.

      - RENTROLLSERVERNOW
        This one can cause considerable confusion if you are not aware of it.
        There is a function called rlib.Now() which is used in some places as
        a replacement for time.Now().  Under VERY special conditions, it can
        return a value which is NOT the system time.  Safeguards have been
        put in place so that this cannot happen in production. But it will
        happen in the development environment. For testing it is used to
        control the "current" date that is used when expanding past instances
        of repeating sequences (assessments, tasklists, ...).  The problem
        with expanding past instances is that as time progresses -- days, weeks,
        and months-- after the tests have been written the number of instances
        created will change. This will cause ASMIDs to change, it will cause
        report output and other output to change significantly over time. Thus,
        the "good" files no longer work (or they would need to be constantly
        updated). To address this, you can set the date that you want
        rlib.Now() to return.  This will cause the expansions to return a
        predictable number of instances and the tests will not need to be
        updated as time progresses.  This variable is used extensively in
        ./raflow/f2ra/functest.sh

13. Within functest.sh there is typically a statement that pulls in all the
    functions in share/base.sh .  You should make use of these functions as they
    will save you a lot of time. There are a few command line options that can
    also save you a lot of time when you are developing the tests or when you
    run them and you find errors. The command-line options will be listed if
    you run ./functest.sh -help .  Here is the output as of this writing. Always
    use the -h option to ensure you see the latest option list.

    $ ./functest.sh -h

    SYNOPSIS
    	./functest.sh [-a -c -f -m -n -o -p  -r -t]

    	Rentroll test script. Compare the output of each step to its associated
    	.gold known-good output. If they miscompare, fail and stop the script.
    	If they match, keep going until all tasks are completed.

    OPTIONS
    	-a  If a test fails, pause after showing diffs from gold files, prompt
    	    for what to do next:  [Enter] to continue, m to move the output file
    	    into gold/ , or Q / X to exit.

    	-c  Show each command that was executed.

    	-f  Executes all the steps of the test but does not compare the output
    	    to the known-good files. This is useful when making a slight change
    	    to something just to see how it will work.

    	-m  Do not run any server mgmt commands. Typically, this is used to
    		run the test commands against an already-running server.

    	-n  Do not create a new database, use the current database and simply
    	    add to it.

    	-o  Regenerate the .gold files based on the output from this run. Only
    	    use this option if you're sure the output is correct. This option
    	    can be a huge time saver, but use it with caution. All .gold files
    	    are maintained in the ././gold/ directory.

    	-p  Causes execution to pause between tests so that you can perform
    	    checks in the database, or in logfiles, or any other output that
    	    the tests cause.

    	-t  Sets the environment variable RUNSINGLETEST to the supplied value. By
    	    default, "x" == "x" and this should cause all of the
    	    tests in the script to run. But if you would like to be able to run
    	    an individual test by name, you can use  to check and
    	    see if the user has requested a specific test. So, to run a single
            test, "b" for example, you would use the following command:

            $ ./functest.sh -t b


TFILES is the name of the test.  Typically we use 'a', 'b', 'c', ...  This
makes it easier to deal with the output files which are numbered for each step
in the test.

You can create a query in many ways. Here are a couple:
1. The old way of doing this was to embed the encoded request data into an 'echo'
statement and redirect the output into a file named 'request'.  You can build
the request data by creating the JSON in some tool then minifying and encoding
it. One tool to use can be found int the RentRoll WebService API docs that are
created in every build. You can access these doc payments by clicking on the
Developer dropdown in the Roller UI top menubar, then click on the Webdocs
menu item. The text area labeled "Payload:" on the right side of the display
can be used to enter JSON, encode or decode it, beautify it, and minify it. You
can then copy/paste it into the functest.sh script.

2. The easiest way as of this writing is to use the "Payload:" text area as
describe above, create and minify the JSON data and pass
it as a parameter to encodeRequest this will create a file named 'request'
which can be passed to 'dojsonPOST' or 'dojsonGET'.  These functions call
curl(1) and save the response in the supplied file name.  Typically, the
supplied file name is "${TFILES}${STEP}"

Examples:

These two lines

    encodeRequest '{"cmd":"get","selected":[],"limit":100,"offset":0}'

    echo "%7B%22cmd%22%3A%22get%22%2C%22selected%22%3A%5B%5D%2C%22limit%22%3A100%2C%22offset%22%3A0%7D" > request

do exactly the same thing, both create a file called 'result' that have
the exact same contents.  The encodeRequest line is a little easier to read
and make changes to. The echo line can be copied from the console output
of the server directly to your test step in functest.sh . The file 'result' is
then used in a curl call to the server to execute the test.  For example:

dojsonPOST "http://localhost:8270/v1/rentableusestatus/1/1" "request" "${TFILES}${STEP}"  "RentableUseStatus-Search"

First param is the url, second is the name of the file containing the payload,
third param is the name of the server response file (by convention, this is the
name of the test followed by the step number), last is a text string describing
this step in the test -- it can be whatever you want, but it must not have any
spaces.

Either way of creating the 'result' file is fine. Use whichever method is
most appropriate for your test. And if you devise a better way of doing this
please document it here!

RUNNING TESTS
-------------
Here are a few examples of how to run the tests in the directories below. There
are more options as described above.

make test		Contains any one-time setup work, eventually
			executes ./functest.sh

./functest.sh           run all functional tests

./functest.sh -t x      runs only test 'x' in the file.  Tests within these
                        files are usually named a, b, c, ...  Some of the
			older ./functest.sh files do have this level of
			granularity.

./functest -a           run the tests and if any test output does not match
                        the expected output show the diffs and ask if the
			new output should become the expected output (m) or
			just continue the test (Enter) or stop the test (q).
